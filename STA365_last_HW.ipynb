{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WorMa4tBwKwV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Describe how the posterior predictive distribution is created for mixture models\n",
        "0. A PyMc model for a number of clusters equal to the number of distributions/chains you're trying to model is created, parametrized on mu and sigma, with weights assigned acordingly, is created and sampled from.\n",
        "1. One of the chains is chosen at random with equal probability. A draw from that chain is also drawn randomly with equal probability.\n",
        "2. Take a number of draws equal to the number of chains times the support from a normal distribution parameteratrized on the mew and sigma of the chain and draw you randomly chose in step 1.\n",
        "3. Weight the draws from step 2 accoridng to the weights of the chosen chain\n",
        "4. Repeat steps 1 through 3 to create the number of posterior predictive distributions you're aiming for."
      ],
      "metadata": {
        "id": "XFYhYNce727B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Describe how to posterior predictive distribution is created in general\n",
        "If you have a conditional likelihood and a single prior that creates a closed-form posterior distribution, you sample from the product of the likelihood and the prior to create the posterior predictive distribution.\n",
        "\n",
        "If you have multiple conditional priors and a conditional likelihood, you alternate sampling between the full conditionals, continually updating the parameters of each full conditional, to create draws from the posterior predictive distribution.\n"
      ],
      "metadata": {
        "id": "ndEtZ3W1CnFD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3. If you were doing a regression of $y$ on $X$, but $X$ had some missing values, how could you perform a Bayesian analysis without throwing away the rows with missing values in $X$\n",
        "1. Choose a prior (probably an uninformative one) to serve as your prior belief about the missing values\n",
        "2. Use the distribution of the data from $X$ that you do know as the likelihood and sample from the posterior distribution created by the product of that likelhiood and the prior from 1\n",
        "3. Impute the values drawn from the posterior in 2 as the missing values in $X$"
      ],
      "metadata": {
        "id": "1cfBXoCUGzHt"
      }
    }
  ]
}